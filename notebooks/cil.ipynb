{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b60e6cb-79bf-4b5a-b25e-d74d2a5fc70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albin/anaconda3/envs/avalanche_experiments/lib/python3.9/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from src.factories.benchmark_factory import create_benchmark\n",
    "from src.toolkit.utils import set_seed\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import omegaconf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "\n",
    "from experiments.lora_forget import MultiClassModel, create_lora_config\n",
    "plt.style.use(\"matplotlibrc.template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033be26-8b41-4434-8c90-e68a855d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from peft import PeftConfig, PeftModel\n",
    "import copy\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_prediction_vector(model, dataloader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Gets the predicted label for a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    correct = []\n",
    "    for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "        mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "        out = model.forward_single_task(mb_x, 0)\n",
    "        all_preds.append(out.argmax(dim=1))\n",
    "        correct.append(mb_y)\n",
    "    \n",
    "    return torch.cat(all_preds), torch.cat(correct)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_dataset(model, dataset, min_class, max_class, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Gets the predicted label for a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=12)\n",
    "    \n",
    "    for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "        mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "        features = model.backbone(mb_x)\n",
    "        out = model.head(features)\n",
    "        out = out[:, min_class:max_class]\n",
    "        correct += (out.argmax(dim=1) == mb_y).float().sum()\n",
    "        total += len(mb_y)\n",
    "        \n",
    "    return correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def cil_accuracy(model, test_stream, task_classes, device=\"cuda\"):\n",
    "    experience_accuracies = []\n",
    "    for tid, exp in enumerate(test_stream):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        dataloader = torch.utils.data.DataLoader(exp.dataset, batch_size=64, shuffle=False, num_workers=12)\n",
    "        for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "            mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "            all_outs = []\n",
    "\n",
    "            # Label adjustment\n",
    "            mb_y = mb_y + sum(task_classes[:tid])\n",
    "\n",
    "            features = model.backbone(mb_x)\n",
    "            \n",
    "            for tid, num_classes in enumerate(task_classes):\n",
    "            \n",
    "                out = model.linear.forward_single_task(features, tid)\n",
    "                all_outs.append(out[:, :num_classes])\n",
    "                \n",
    "            actual_out = torch.cat(all_outs, dim=1)\n",
    "            correct += (actual_out.argmax(dim=1) == mb_y).float().sum()\n",
    "            total += len(mb_y)\n",
    "\n",
    "        experience_accuracies.append(correct / total)\n",
    "\n",
    "    return experience_accuracies\n",
    "            \n",
    "\n",
    "def iterate_models(model, basepath, merge=True):\n",
    "    # We just need to merge the LoRAs and check\n",
    "    path_dict = {}\n",
    "    output_model = copy.deepcopy(model)\n",
    "    \n",
    "    for root, dirs, files in os.walk(basepath):\n",
    "        for f in files:\n",
    "            if \"adapter_model\" in f:\n",
    "                # Split the path by '/'\n",
    "                split_path = root.split('/')\n",
    "\n",
    "                # Get the last element which contains the number\n",
    "                last_element = split_path[-1]\n",
    "\n",
    "                # Extract the number\n",
    "                number = int(last_element.split('_')[-1])\n",
    "\n",
    "                # Create the dictionary\n",
    "                path_dict[number] = root\n",
    "                \n",
    "    path_dict = dict(sorted(path_dict.items()))\n",
    "\n",
    "    for rank, path in path_dict.items():\n",
    "        print(path)\n",
    "        lora_config = PeftConfig.from_pretrained(path)\n",
    "        output_model.backbone = PeftModel.from_pretrained(output_model.backbone, model_id=path, config=lora_config)\n",
    "        yield output_model\n",
    "\n",
    "        # Merge previous one and load next one\n",
    "        if merge:\n",
    "            output_model.backbone = output_model.backbone.merge_and_unload()\n",
    "        else:\n",
    "            output_model.backbone = output_model.backbone.unload()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e181cb-75b3-4a80-98fb-43e2ffd4b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load model And Scenario\n",
    "\n",
    "basepath = \"/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/\"\n",
    "rank = 6\n",
    "path = os.path.join(basepath, f\"lora_forget_{rank}\")\n",
    "\n",
    "config = omegaconf.OmegaConf.load(os.path.join(path, \"config.yaml\"))\n",
    "\n",
    "# Replace datadir and results dir\n",
    "config.benchmark.dataset_root = \"/DATA/data\"\n",
    "\n",
    "set_seed(config.experiment.seed)\n",
    "\n",
    "model_id = config.model.model_id\n",
    "\n",
    "model = timm.create_model(model_id, pretrained=True, num_classes=1000)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "train_transforms = timm.data.create_transform(**data_config, is_training=True)\n",
    "eval_transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "if config.benchmark.factory_args.use_transforms:\n",
    "    transforms = (train_transforms, eval_transforms)\n",
    "else:\n",
    "    transforms = (eval_transforms, eval_transforms)\n",
    "\n",
    "head_name = \"head\" if config.model.model_type == \"vit\" else \"fc\"\n",
    "\n",
    "model = MultiClassModel(model, head_name, config.model.model_type)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# Avalanche: Create Scenario\n",
    "\n",
    "scenario = create_benchmark(\n",
    "    config.benchmark.factory_args.benchmark_name,\n",
    "    n_experiences=1,\n",
    "    shuffle=False,\n",
    "    dataset_root=config.benchmark.dataset_root,\n",
    "    override_transforms=transforms,\n",
    ")\n",
    "\n",
    "# Load final head\n",
    "setattr(model, head_name, torch.load(os.path.join(path, \"head.ckpt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149570c7-c5e3-4914-8898-0ed9e4895560",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_classes = [len(exp.classes_in_this_experience) for exp in scenario.train_stream]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09f88d-b22c-45a4-82a8-18db1b9899bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute cil accuracies (without probing)\n",
    "\n",
    "accuracies = []\n",
    "model_iterator = iterate_models(model, path, merge=True)\n",
    "for tid, model in enumerate(model_iterator):\n",
    "    accuracies.append(cil_accuracy(model, scenario.test_stream[:tid+1], task_classes[:tid+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c18580f-0689-47f2-8163-ac9adee3c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repair heads and build cil head from existing weights\n",
    "import torch.nn as nn\n",
    "\n",
    "cil_head = nn.Linear(model.head.classifiers[\"0\"].classifier.in_features, sum(task_classes))\n",
    "\n",
    "# Load existing weights into single head\n",
    "current_index = 0\n",
    "for tid, mt_head in model.head.classifiers.items():\n",
    "    num_classes = task_classes[int(tid)]\n",
    "    cil_head.weight.data[current_index:current_index+num_classes, :].copy_(mt_head.classifier.weight[:num_classes, :])\n",
    "    current_index = current_index + num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2455a00e-7ff7-45aa-9d77-6cbc67b2485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/lora_forget_6/lora_0\n",
      "/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/lora_forget_6/lora_1\n",
      "/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/lora_forget_6/lora_2\n",
      "/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/lora_forget_6/lora_3\n",
      "/DATA/avalanche_experiments/old_lora/lora_vit_with_saved_loras/lora_forget_6/lora_4\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy on aircraft\n",
    "\n",
    "model_iterator = iterate_models(model, path, merge=True)\n",
    "\n",
    "# Imnet\n",
    "\n",
    "loaded_model = next(model_iterator)\n",
    "\n",
    "# Cars\n",
    "\n",
    "loaded_model = next(model_iterator)\n",
    "\n",
    "# Flowers\n",
    "\n",
    "loaded_model = next(model_iterator)\n",
    "\n",
    "# Aircraft\n",
    "\n",
    "loaded_model = next(model_iterator)\n",
    "\n",
    "# Birds\n",
    "\n",
    "loaded_model = next(model_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b5965b-1f66-4462-9f08-1d0978b99ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new head as head\n",
    "\n",
    "loaded_model.head = cil_head\n",
    "loaded_model = loaded_model.cuda()\n",
    "\n",
    "if os.path.exists(os.path.join(path, \"cil_head.ckpt\")):\n",
    "    print(\"Found existing head\")\n",
    "    loaded_model.head = torch.load(os.path.join(path, \"cil_head.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ada809-0bb2-40c2-b00d-8af213b66772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy on aircraft as a check\n",
    "\n",
    "task_id = 3\n",
    "\n",
    "aircraft_test = scenario.test_stream[task_id].dataset\n",
    "\n",
    "accuracy = eval_dataset(loaded_model, aircraft_test, min_class = sum(task_classes[:task_id]), max_class = sum(task_classes[:task_id + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5827a2d0-a2c8-44bd-ab00-5905636b1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing\n",
    "\n",
    "from avalanche.benchmarks.utils.data_loader import TaskBalancedDataLoader\n",
    "\n",
    "task_classes = [len(exp.classes_in_this_experience) for exp in scenario.test_stream]\n",
    "\n",
    "def map_offset(labels, task_labels):\n",
    "    for tid in torch.unique(task_labels):\n",
    "        offset = sum(task_classes[:tid])\n",
    "        labels[task_labels == tid] = labels[task_labels == tid] + offset\n",
    "    return labels\n",
    "\n",
    "# Create full training dataset\n",
    "new_ds = None\n",
    "for exp in scenario.train_stream:\n",
    "    if new_ds is None:\n",
    "        new_ds = exp.dataset\n",
    "    else:\n",
    "        new_ds = new_ds.concat(exp.dataset)\n",
    "\n",
    "dataloader = TaskBalancedDataLoader(new_ds, batch_size=64, distributed_sampling=False, oversample_small_groups=True, num_workers=12, shuffle=True)\n",
    "\n",
    "# Freeze BB\n",
    "for p in loaded_model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "    p.grad = None\n",
    "\n",
    "# Unfreeze Head\n",
    "for p in loaded_model.head.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e84937-a6b2-40e2-bf7f-e196e6fc0a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                   | 3000/98552 [20:04<10:39:22,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train with probing\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_iters = 3000\n",
    "device = \"cuda\"\n",
    "\n",
    "optimizer = torch.optim.Adam(loaded_model.parameters(), lr=0.001)\n",
    "\n",
    "loaded_model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "total_iters = 0\n",
    "for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "    mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = loaded_model.backbone(mb_x)\n",
    "\n",
    "    out = loaded_model.head(features)\n",
    "\n",
    "    mapped_labels = map_offset(mb_y, mb_tid)\n",
    "\n",
    "    loss = F.cross_entropy(out, mapped_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(float(loss.detach().cpu()))\n",
    "\n",
    "    total_iters += 1\n",
    "    if total_iters > num_iters:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50735a45-cc7b-4461-8a99-4b1ae06d3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader\n",
    "for mb_x, mb_y, mb_tid in dataloader:\n",
    "    print(mb_tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cfa1f-9261-4545-9c11-cda7ecb8fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_offset(mb_y, mb_tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f42e97-0c96-4ec7-832b-d8653ef4bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_dataset_cil(model, dataset, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Gets the predicted label for a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=12)\n",
    "    \n",
    "    for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "        mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "\n",
    "        mb_y = map_offset(mb_y, mb_tid)\n",
    "        \n",
    "        features = model.backbone(mb_x)\n",
    "        out = model.head(features)\n",
    "        correct += (out.argmax(dim=1) == mb_y).float().sum()\n",
    "        total += len(mb_y)\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aed2680-1410-4033-bd24-586fb96e1635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 782/782 [04:28<00:00,  2.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:48<00:00,  2.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97/97 [00:37<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 53/53 [00:48<00:00,  1.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 91/91 [00:35<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for exp in scenario.test_stream:\n",
    "    acc = eval_dataset_cil(loaded_model, exp.dataset)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562100d1-adb6-453b-8461-49ff4f170eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6462, device='cuda:0'),\n",
       " tensor(0.6574, device='cuda:0'),\n",
       " tensor(0.8855, device='cuda:0'),\n",
       " tensor(0.5323, device='cuda:0'),\n",
       " tensor(0.7282, device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21d5d07a-eb97-414d-8ae4-7f0176a0f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6899, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Rank: {rank}\")\n",
    "torch.stack(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb148a-f58f-4d9d-8b92-067f62d25492",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(loaded_model.head, os.path.join(path, \"cil_head.ckpt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

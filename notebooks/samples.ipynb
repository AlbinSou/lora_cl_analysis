{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd49a28-8d64-48c2-b70c-9d36b60f9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from src.factories.benchmark_factory import create_benchmark\n",
    "from src.toolkit.utils import set_seed\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import omegaconf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from experiments.lora_forget import MultiClassModel, create_lora_config\n",
    "plt.style.use(\"matplotlibrc.template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71f1e3-b5be-421c-a666-76d797119c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from peft import PeftConfig, PeftModel\n",
    "import copy\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_prediction_vector(model, dataloader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Gets the predicted label for a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    correct = []\n",
    "    for mb_x, mb_y, mb_tid in tqdm.tqdm(dataloader):\n",
    "        mb_x, mb_y, mb_tid = mb_x.to(device), mb_y.to(device), mb_tid.to(device)\n",
    "        out = model.forward_single_task(mb_x, 0)\n",
    "        all_preds.append(out.argmax(dim=1))\n",
    "        correct.append(mb_y)\n",
    "    \n",
    "    return torch.cat(all_preds), torch.cat(correct)\n",
    "\n",
    "def iterate_models(model, basepath, merge=True):\n",
    "    # We just need to merge the LoRAs and check\n",
    "    path_dict = {}\n",
    "    output_model = copy.deepcopy(model)\n",
    "    \n",
    "    for root, dirs, files in os.walk(basepath):\n",
    "        for f in files:\n",
    "            if \"adapter_model\" in f:\n",
    "                # Split the path by '/'\n",
    "                split_path = root.split('/')\n",
    "\n",
    "                # Get the last element which contains the number\n",
    "                last_element = split_path[-1]\n",
    "\n",
    "                # Extract the number\n",
    "                number = int(last_element.split('_')[-1])\n",
    "\n",
    "                # Create the dictionary\n",
    "                path_dict[number] = root\n",
    "                \n",
    "    path_dict = dict(sorted(path_dict.items()))\n",
    "\n",
    "    for rank, path in path_dict.items():\n",
    "        print(path)\n",
    "        lora_config = PeftConfig.from_pretrained(path)\n",
    "        output_model.backbone = PeftModel.from_pretrained(output_model.backbone, model_id=path, config=lora_config)\n",
    "        yield output_model\n",
    "\n",
    "        # Merge previous one and load next one\n",
    "        if merge:\n",
    "            output_model.backbone = output_model.backbone.merge_and_unload()\n",
    "        else:\n",
    "            output_model.backbone = output_model.backbone.unload()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0322b9b-9c61-4048-af59-d0bf8656b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model And Scenario\n",
    "\n",
    "basepath = \"/DATA/avalanche_experiments/lora_vit_seeds/\"\n",
    "rank = 32\n",
    "path = os.path.join(basepath, f\"lora_forget_{rank}\", \"0\")\n",
    "#path = \"/DATA/avalanche_experiments/lora_1step_ft/\"\n",
    "\n",
    "config = omegaconf.OmegaConf.load(os.path.join(path, \"config.yaml\"))\n",
    "\n",
    "# Replace datadir and results dir\n",
    "config.benchmark.dataset_root = \"/DATA/data\"\n",
    "\n",
    "set_seed(config.experiment.seed)\n",
    "\n",
    "model_id = config.model.model_id\n",
    "\n",
    "model = timm.create_model(model_id, pretrained=True, num_classes=1000)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "train_transforms = timm.data.create_transform(**data_config, is_training=True)\n",
    "eval_transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "if config.benchmark.factory_args.use_transforms:\n",
    "    transforms = (train_transforms, eval_transforms)\n",
    "else:\n",
    "    transforms = (eval_transforms, eval_transforms)\n",
    "\n",
    "head_name = \"head\" if config.model.model_type == \"vit\" else \"fc\"\n",
    "\n",
    "model = MultiClassModel(model, head_name, config.model.model_type)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# Avalanche: Create Scenario\n",
    "\n",
    "scenario = create_benchmark(\n",
    "    config.benchmark.factory_args.benchmark_name,\n",
    "    n_experiences=1,\n",
    "    shuffle=False,\n",
    "    dataset_root=config.benchmark.dataset_root,\n",
    "    override_transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3c88c-28c8-434d-8678-f9079f49dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.datasets.imagenet_data import IMAGENET_TORCHVISION_CLASSES\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "imagenet = scenario.test_stream[0]\n",
    "\n",
    "# There are several classes per label, 1.8 in average\n",
    "\n",
    "IDX_TO_CLASS = {i:c for i, c in enumerate(IMAGENET_TORCHVISION_CLASSES)}\n",
    "\n",
    "# Test to check category correctness\n",
    "idx = 134\n",
    "\n",
    "plt.imshow(torch.permute(imagenet.dataset[idx][0], (1, 2, 0)))\n",
    "label = imagenet.dataset[idx][1]\n",
    "print(label)\n",
    "print(IDX_TO_CLASS[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0615e-33bd-4c93-9c65-2aa14d2b0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction vector and true labels vector for vanilla model\n",
    "\n",
    "# Create some subset of the test set\n",
    "\n",
    "loader = torch.utils.data.DataLoader(imagenet.dataset, batch_size=config.strategy.train_mb_size, shuffle=False)\n",
    "pred_vect, correct = get_prediction_vector(model, loader)\n",
    "acc = (pred_vect == correct).float().mean()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8261c14-83f4-4b52-a891-4222234e669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_iterator = iterate_models(model, path)\n",
    "model_iterator = iterate_models(model, path, merge=False)\n",
    "\n",
    "# Imnet\n",
    "m = next(model_iterator)\n",
    "\n",
    "# Cars\n",
    "m = next(model_iterator)\n",
    "\n",
    "# Flowers\n",
    "#m = next(model_iterator)\n",
    "\n",
    "# Aircraft\n",
    "#m = next(model_iterator)\n",
    "\n",
    "# Birds\n",
    "#m = next(model_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b92de-0a50-41fd-929f-3aa98a423f01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load probed head\n",
    "probed_head = torch.load(os.path.join(path, \"head_probed_1.ckpt\"))\n",
    "m.head = probed_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52635f05-f03c-435e-acb7-292a36f0a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction vector and true labels vector for model finetuned on Stanford Cars\n",
    "\n",
    "loader = torch.utils.data.DataLoader(imagenet.dataset, batch_size=config.strategy.train_mb_size, shuffle=False)\n",
    "pred_vect_new, correct = get_prediction_vector(m, loader)\n",
    "acc = (pred_vect_new == correct).float().mean()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd94865-059a-4c6b-9db1-37108fc233b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load New errors\n",
    "diff = (pred_vect_new != correct) & (pred_vect == correct)\n",
    "\n",
    "words = []\n",
    "mode = \"error\"\n",
    "for label in correct[diff]:\n",
    "    words.append(\" \".join(IDX_TO_CLASS[int(label)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43397d-34dd-446e-aa43-448dc6a92513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load New correct\n",
    "diff = (pred_vect != correct) & (pred_vect_new == correct)\n",
    "\n",
    "words = []\n",
    "mode = \"correct\"\n",
    "for label in correct[diff]:\n",
    "    words.append(\" \".join(IDX_TO_CLASS[int(label)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168815a3-39e7-4ce6-b302-bf24c4549440",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load old errors\n",
    "diff = (pred_vect_old != correct) & (pred_vect == correct)\n",
    "\n",
    "words_error = []\n",
    "mode = \"error\"\n",
    "for label in correct[diff]:\n",
    "    words_error.append(\" \".join(IDX_TO_CLASS[int(label)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999452ea-480c-484e-aa40-8e7906be38da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load New correct FROM PROBED\n",
    "diff = (pred_vect == correct) & (pred_vect_old != correct) & (pred_vect_new == correct)\n",
    "\n",
    "words = []\n",
    "mode = \"correct\"\n",
    "for label in correct[diff]:\n",
    "    words.append(\" \".join(IDX_TO_CLASS[int(label)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98248554-acd8-4e79-8d1b-4e5b4a717542",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fbbb6-0e2d-4d42-8f4f-9d35f9ac5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Count the classes with biggest increase // decrease\n",
    "class_counts = defaultdict(lambda: 0)\n",
    "\n",
    "for label in correct[diff]:\n",
    "    categories = IDX_TO_CLASS[int(label)]\n",
    "    class_counts[\" & \".join(categories)] += 1\n",
    "    \n",
    "topk = 20\n",
    "\n",
    "sorted_counts = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "\n",
    "# Extract category names and counts from sorted list\n",
    "categories = [item[0].split(\"&\")[0] for item in sorted_counts]\n",
    "counts = [item[1] for item in sorted_counts]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(categories, counts, color='lightcoral')\n",
    "#plt.xlabel('Categories')\n",
    "#plt.ylabel('Counts')\n",
    "plt.title(f'Top {topk} Class Counts', size=20)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d10ab8-c412-4642-a513-adf00554f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to get the similarity between two words\n",
    "def word_similarity(word1, word2):\n",
    "    # Get synsets for each word\n",
    "    synsets1 = wordnet.synsets(word1)\n",
    "    synsets2 = wordnet.synsets(word2)\n",
    "\n",
    "    max_similarity = 0\n",
    "\n",
    "    # Calculate similarity between each pair of synsets\n",
    "    for synset1 in synsets1:\n",
    "        for synset2 in synsets2:\n",
    "            similarity = synset1.wup_similarity(synset2)\n",
    "            if similarity is not None and similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "\n",
    "    return max_similarity\n",
    "\n",
    "# Function to split a sentence into words and average the similarity with a target word\n",
    "def average_similarity(sentence, target_word):\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    total_similarity = 0\n",
    "    word_count = 0\n",
    "\n",
    "    # Calculate similarity for each word in the sentence\n",
    "    for word in words:\n",
    "        similarity = word_similarity(word, target_word)\n",
    "        if similarity > 0:  # Skip words without any similarity\n",
    "            total_similarity += similarity\n",
    "            word_count += 1\n",
    "\n",
    "    # Compute average similarity\n",
    "    if word_count > 0:\n",
    "        average_similarity = total_similarity / word_count\n",
    "        return average_similarity\n",
    "    else:\n",
    "        return 0  # Return 0 if no words with similarity were found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb7f56-8229-47b9-be65-aab9397206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similarities = []\n",
    "similarities = []\n",
    "\n",
    "target_word = \"car\"\n",
    "\n",
    "# On full imagenet categories\n",
    "for label, w in IDX_TO_CLASS.items():\n",
    "    sim = average_similarity(\" \".join(w), target_word)\n",
    "    all_similarities.append(sim)\n",
    "\n",
    "for w in words:\n",
    "    sim = average_similarity(w, target_word)\n",
    "    similarities.append(sim)\n",
    "\n",
    "assert len(similarities) == len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2459a6-1ca6-4b6f-89e5-146cfc05ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "ax = sns.kdeplot(similarities, label=f\"New {mode} Categories\", legend=True)\n",
    "sns.kdeplot(all_similarities, label=f\"All Imagenet Categories\", legend=True)\n",
    "ax.legend()\n",
    "sns.move_legend(ax, loc=\"lower left\")\n",
    "plt.xlabel(f\"Similarity to word {target_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4240795-2d3d-4139-b18b-5bf25cd368bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correct, pred, pred_vect\n",
    "\n",
    "torch.save([correct, pred_vect, pred_vect_new], \"./predvects_os_airplanes.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d4da6-6596-4901-88f2-1b4ed2c555e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous\n",
    "\n",
    "correct_old, pred_vect, pred_vect_new = torch.load(\"./predvects_os_cars.ckpt\")\n",
    "#(correct.cpu() == correct_old.cpu()).sum()\n",
    "\n",
    "correct_old = correct_old.cuda()\n",
    "pred_vect = pred_vect.cuda()\n",
    "pred_vect_new = pred_vect_new.cuda()\n",
    "\n",
    "correct = correct_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca6524-9006-4c58-b462-6a8d8eb1f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_vect_new == correct_old).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b404fd-665e-4a7d-8c71-2de419630277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41673a-ca00-42f8-b545-9f4b633de964",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word = \"car\"\n",
    "counts = []\n",
    "sims = []\n",
    "for w, count in word_counts.items():\n",
    "    sim = average_similarity(w, target_word)\n",
    "    sims.append(sim)\n",
    "    counts.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9606942-1ba0-46d8-a9a1-efb520a8deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=sims, y=counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
